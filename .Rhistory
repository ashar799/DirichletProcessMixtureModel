######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.7
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.05
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
library(FacPad)
?FacPad
library(sparcl)
k
F
km.perm <- KMeansSparseCluster(x = Y.data, K= F, wbounds = NULL, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
km.perm <- KMeansSparseCluster(x = Y.dat, K= F, wbounds = NULL, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
km.perm
D
km.perm$ws
rel.D
km.perm <- KMeansSparseCluster(x = Y.dat, K= F, wbounds = rel.D, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
print(km.perm)
rel.D
D
km.perm <- KMeansSparseCluster(x = Y.dat, K= F, wbounds = 5, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
km.perm
print(km.perm)
per <- KMeansSparseCluster.permute(Y.dat,K=F,wbounds=seq(2,5,len=8),nperms=3)
per$bestw
per
D
per <- KMeansSparseCluster.permute(Y.dat,K=F,wbounds=seq(1,2,len=10),nperms=5)
per <- KMeansSparseCluster.permute(Y.dat,K=F,wbounds=seq(1.1,2,len=10),nperms=5)
per
per <- KMeansSparseCluster.permute(Y.dat,K=F,wbounds=seq(1.1,1.5,len=100),nperms=5)
per
rel.D
per$bestw
km.perm <- KMeansSparseCluster(x = Y.dat, K= F, wbounds = 1.5, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
km.perm
km.perm$ws
km.perm$clust
km.perm$Cs
print(km.perm)
unlist(km.perm)
per <- KMeansSparseCluster.permute(Y.dat,K=F,wbounds=seq(1.1,1.7,len=100),nperms=5)
per$bestw
km.perm <- KMeansSparseCluster(x = Y.dat, K= F, wbounds = per$bestw, nstart = 20, silent = FALSE, maxiter=6, centers=NULL)
km.perm$ws
ws(km.perm)
unlist(km.perm)[1:D]
weight <- unlist(km.perm)[1:D]
clustering <-unlist(km.perm)[D+1:D+N]
weight
clustering
unlist(km.perm)[(D+1):(D+N)]
weight <- unlist(km.perm)[1:D]
clustering <-unlist(km.perm)[(D+1):(D+N)]
which(weight!=0)
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.7
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.05
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
############################# PARAMETERS for GIBB's SAMPLING ####
iter = 100
iter.burnin = 200
iter.thin  =5
k = 3
########################### Initialize the functions ############
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
D
rel.D
c
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
plot(loglikli)
source('gibbsDPMM.R')
gibbsDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.9
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.9
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.9
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 100
## Total Percentage of irrelevant feature
prob.noise.feature = 0.9
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
############################# PARAMETERS for GIBB's SAMPLING ####
iter = 100
iter.burnin = 200
iter.thin  =5
k = 3
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
dim(Y)
rel.D
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
source('gibbsDPMM.R')
gibbsDPMM()
iter = 50
source('gibbsDPMM.R')
gibbsDPMM()
########## Analyze the fit ##########################################
source('SIManalyzeDPMM.R')
SIManalyzeDPMM()
Nps = as.integer(iter/ iter.thin)
count <- Nps
final.rand <- c(0)
############ The Matrices that will store the results #################################################
final.rand <- c(0)
cindex.final <- c(0)
brier.final <- matrix(NA, nrow = Nps, ncol = F)
################ Begin Analysig the MCMC samples #######################################################
require(Hmisc)
for (h in 1:Nps){
### Adjusted Rand Indices
final.rand[h] <- adjustedRandIndex(c.list[[h]],as.factor(c.true))
### See C-Index (concordance index)
surv.aft <- Surv(time,censoring)
library(Hmisc)
### Predict Time from the model
source('predictlinear.R')
tem.tim <- as.vector(unlist(predictlinear(c.list[[h]], Y, That.list[[h]], Time, beta0.list[[h]], betahat.list[[h]], sigma2.list[[h]])))
library(Hmisc)
cindex.final[h] <-  survConcordance(surv.aft ~ exp(-tem.tim))[[1]]
### Brier Scores
for ( v in 1:F){
ind <- which((c.list[[h]] == v))
time.tmp <- time[ind]
censoring.tmp <- censoring[ind]
Y.tmp <- Y[ind,]
rownames(Y.tmp) <- as.character(c(1:nrow(Y.tmp)))
smod <-  Surv(exp(time.tmp), censoring.tmp)
L = length(ind)
linear.pred <- tem.tim[ind]
sigma.pred <- log(sqrt(sigma2.list[[h]][v]))
### The survival function in AFT model
S1 <- function (times = NULL, lp = NULL, parms = sigma.pred)
{
t.trans <- logb(times)
names(t.trans) <- format(times)
1 - pnorm((t.trans - lp)/exp(parms))
}
mat.tmp <- matrix(NA, nrow = L, ncol = L)
for (j in 1:L){
mat.tmp[,j] <- S1(exp(time.tmp[j]),lp =tem.tim[ind])
}
brier.final[h,v] <- sbrier(smod,mat.tmp, exp(time.tmp))[1]
}
}
cindex.final
final.rand
##### Class Assignments ########################
c.matrix <- matrix(NA, nrow = N, ncol = count)
for ( i in 1:count){
c.matrix[,i] <- c.list[[i]]
}
c.final <- apply(c.matrix,1,median)
############ Time Covariate Slopes FOR Relevant Clusters ############
list.betahat <- list(0)
for ( i in 1:count){
list.betahat[[i]] <- (betahat.list[[i]][1:F,] != 0) +0
}
matrix.betahat <- array(data = NA, dim =c(F,count,D))
for ( z in 1:F){
for ( x  in 1:count){
matrix.betahat[z,x,] <- list.betahat[[x]][z,]
}
}
final.betahat <- apply(matrix.betahat,c(1,3),mean)
heatmapdata <- as.data.frame(final.betahat)
heatmap.2(t(as.matrix(heatmapdata)),dendrogram="none", col =cm.colors(180), margins=c(6,10), main = "Posterior prob. \n for Selection \n in 1 Simulation ", cexCol = 0.85, cexRow = 0.7, Rowv = FALSE)
final.rand <<- final.rand
cindex.final <<- cindex.final
brier.final <<- brier.final
c.final <<- c.final
final.betahat <<- final.betahat
brier.final
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 500
## Total Percentage of irrelevant feature
prob.noise.feature = 0.9
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
## Total Percentage of irrelevant feature
prob.noise.feature = 0.95
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
############################# PARAMETERS for GIBB's SAMPLING ####
iter = 50
iter.burnin = 200
iter.thin  =5
k = 3
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
D
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
beta
c
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 200
## Total Percentage of irrelevant feature
prob.noise.feature = 0.95
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
############################# PARAMETERS for GIBB's SAMPLING ####
iter = 50
iter.burnin = 200
iter.thin  =5
k = 3
########################### Initialize the functions ############
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
D
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
source('gibbsDPMM.R')
gibbsDPMM()
########## Analyze the fit ##########################################
source('SIManalyzeDPMM.R')
SIManalyzeDPMM()
######## Predict on New Data Set #####################################
source('predictCLASS.R')
predictCLASS(Y.new, time.new)
adjustedRandIndex(apply(posteriorprob,1,which.max),c.true.new)
source('predictchineseAFTtime.R')
predictchineseAFTtime(Y.new)
as.vector(post.time.avg)
as.vector(time.real.new)
survConcordance(Surv(time.new,censoring.new) ~ exp(-post.time.avg))[1]
### This simulation Checks if the model can predict well with 10 Dimensions
### Also CHECK THE TIME REQUIRED FOR THE MODEL
### Remove The Past
rm(list = ls())
#################################### SIMULATED DATA PROPERTIES ####################################################
## Number of points
N.test = 150
N.train =150
## Number of Clusters
F = 3
## Distribution of the points within three clusters
p.dist = c(0.4,0.3,0.3)
## Total Number of features D
D = 200
## Total Percentage of irrelevant feature
prob.noise.feature = 0.95
## Overlap between Cluster of molecular Data of the relevant features
prob.overlap = 0.20
###### Get the Data #####################################
## Initialize the Training Data
source('simulateDPMM.R')
simulateDPMM()
############################# PARAMETERS for GIBB's SAMPLING ####
iter = 50
iter.burnin = 200
iter.thin  =5
k = 3
########################### Initialize the functions ############
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
iter = 30
iter.thin  = 3
source('gibbsDPMM.R')
gibbsDPMM()
########## Analyze the fit ##########################################
source('SIManalyzeDPMM.R')
SIManalyzeDPMM()
rel.D
c
adjustedRandIndex(c,c.true)
iter = 30
iter.burnin = 50
iter.thin  = 3
k = 3
######################### Initialize the Parameters ################
source('initializeDPMM.R')
initializeDPMM()
######### Ground Truth ##############################
source('SIMgroundtruth.R')
SIMgroundtruth()
########### Train the Model #########################################
source('burninDPMM.R')
burninDPMM()
D
source('gibbsDPMM.R')
gibbsDPMM()
########## Analyze the fit ##########################################
source('SIManalyzeDPMM.R')
SIManalyzeDPMM()
######## Predict on New Data Set #####################################
source('predictCLASS.R')
predictCLASS(Y.new, time.new)
## Check how much concordance is there
test.randindex <- adjustedRandIndex(apply(posteriorprob,1,which.max),c.true.new)
source('predictchineseAFTtime.R')
predictchineseAFTtime(Y.new)
## Do a Non parametric test
predicted.cindex <- survConcordance(Surv(time.new,censoring.new) ~ exp(-post.time.avg))[1]
predicted.cindex
dim(Y)
gr.flx <- flexmix(time ~ Y, k =F)
gr.flx.rand <- adjustedRandIndex(c.true,clusters(gr.flx))
########## CoxPH #############################
fit.cox.flx <- coxph(smod ~ Y[,1:D]*strata(as.factor(clusters(gr.flx))), data = as.data.frame(Y))
## C-Index
cindex.flx.cox <- survConcordance(smod ~ predict(fit.cox.flx))[1]
## Brier Score
fit.coxph <- survfit(fit.cox.flx, newdata = as.data.frame(Y[,1:D]))
#brier.flx.cox <- sbrier(Surv(fit.coxph$time,fit.coxph$n.event), fit.coxph$surv)[[1]]
smod <-  Surv(exp(time), censoring)
cindex.flx.cox <- survConcordance(smod ~ predict(fit.cox.flx))[1]
## Brier Score
fit.coxph <- survfit(fit.cox.flx, newdata = as.data.frame(Y[,1:D]))
#brier.flx.cox <- sbrier(Surv(fit.coxph$time,fit.coxph$n.event), fit.coxph$surv)[[1]]
fit.cox.flx <- coxph(smod ~ Y[,1:D]*strata(as.factor(clusters(gr.flx))), data = as.data.frame(Y))
## C-Index
cindex.flx.cox <- survConcordance(smod ~ predict(fit.cox.flx))[1]
## Brier Score
fit.coxph <- survfit(fit.cox.flx, newdata = as.data.frame(Y[,1:D]))
#brier.flx.cox <- sbrier(Surv(fit.coxph$time,fit.coxph$n.event), fit.coxph$surv)[[1]]
gr.flx.rand.final <<- gr.flx.rand
cindex.flx.cox.final <<- as.numeric(cindex.flx.cox)
#brier.flx.cox.final <<-  brier.flx.cox
install.packages("NMF")
install.packages("NMF")
library(nmf)
library(NMF)
library("NMF")
install.packages("NMF")
library(NMF)
library(nmf)
library('NMF')
install.packages("NMF")
library('NMF')
library(nmf)
library('NMF')
library(NMF)
install.packages('NMF')
?nmf
?nmf()
library('NMF')
library(NMF)
save(list =ls(), file = 'Simulations.RData')
