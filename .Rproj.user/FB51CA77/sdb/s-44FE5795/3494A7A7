{
    "contents" : "## Testing the DPplusAFT model with Gibb's Sampling\n### Script to test if the model works with higher dimensions\n## With irrelevant features and with Time Censoring \n\nrm(list = ls())\n## setwd('/home/bit/ashar/Dropbox/Code/DPmixturemodel/DPplusAFT')\n\nlibrary(MASS)\nlibrary(mixtools)\nlibrary(matrixcalc)\nlibrary(stats)\nlibrary(Runuran)\nlibrary(truncnorm)\nlibrary(Matrix)\nlibrary(MCMCpack)\nlibrary(psych)\nlibrary(VGAM)\nlibrary(MixSim)\nlibrary(statmod)\nlibrary(flexclust)\nlibrary(survcomp)\nlibrary(mixAK)\nlibrary(mclust)\nlibrary(monomvn)\n\n\n#################################### SIMULATED DATA PROPERTIES ####################################################\n## Number of points\nN = 120\n\n## Number of Clusters\nF = 2\n\n## Distribution of the points within three clusters\n\np.dist = c(0.6,0.4)\n\n## Total Number of features D\n\nD = 50\n\n## Total Percentage of irrelevant feature\n\nprob.noise.feature = 0.90\n\n## Total Percentage of censoring\n\nprob.censoring = 0.05\n\n\n## Overlap between Cluster of molecular Data of the relevant features\n\nprob.overlap = 0.05\n\n## Percentage of Noise/Overlap in Time Data\n\nprob.noise = 0.05\n\n## Actual Number of Components and dimension  which are relevant\nrel.D = as.integer(D* (1-prob.noise.feature))\n## Actual Number of Irrelevant Componenets\nirrel.D = D - rel.D\n\n\n########################################Simulated Data##############################################\nA <- MixSim(MaxOmega = prob.overlap ,K = F, p = rel.D, int =c(0,10), lim = 1e08)\n\n\ndata.mu = array(data = NA, dim =c(F,D))\ndata.S = array(data = NA, dim =c(F,D,D))\n\nfor( i in 1:F){\n  data.mu[i,1:rel.D] <- A$Mu[i,1:rel.D]\n  data.S[i,1:rel.D,1:rel.D] <- A$S[1:rel.D,1:rel.D,i]\n}\n\n## Initializing the points\n# Y.list <- list(0)\n# for ( i in 1:F){\n# Y.list[[i]] <- matrix(0, nrow =  as.integer(N * p.dist[i]), ncol = D)\n# }\n\n# ## The relevant data is genereated first\n# Y.list <- list(0)\n# for ( i in 1:F){\n#   Y.list[[i]] <- mvrnorm(n = as.integer(N * p.dist[i]), mu = data.mu[i,1:D], Sigma = diag(x =1, nrow = D, ncol = D))\n# }\n# \n\n## The relevant data is genereated first\nY.rel.list <- list(0)\nfor ( i in 1:F){\n  Y.rel.list[[i]] <- mvrnorm(n = as.integer(N * p.dist[i]), mu = data.mu[i,1:rel.D], Sigma = data.S[i,1:rel.D,1:rel.D])\n}\n\n## Scaling the Data as ONLY the scaled data will be used for generating the times\nY.rel.sc.list <- list(0)\nfor ( i in 1:F){\n  Y.rel.sc.list[[i]] <- scale(Y.rel.list[[i]], center = TRUE, scale = TRUE)\n}\n\n## Irrelevant features\nY.irrel.list <- list(0)\nfor ( i in 1:F){\n  mean <- runif(irrel.D,0,10)\n  Y.irrel.list[[i]] <- mvrnorm(n = as.integer(N * p.dist[i]), mu = mean, Sigma = diag(x =1, nrow = irrel.D, ncol = irrel.D))\n}\n\n\n## The Co-efficients have to be obtained from uniform distribution between [1,10]\nbeta.list <- list(0)\nfor ( i in 1:F){\nbeta.list[[i]] <- runif(rel.D, min = -5, max = 5)\n}\n\n# order.rel <- list(0)\n# for (i in 1:F){\n# order.rel[[i]] <- sample(D, rel.D)  \n# }\n\n\n## The relevant data is \n#  Y.rel.list <- list(0)\n# for ( i in 1:F){\n#   Y.rel.list[[i]] <- Y.list[[i]][,order.rel[[i]]]\n# }\n\n# ## Scaling the Data as ONLY the scaled data will be used for generating the times\n# Y.rel.sc.list <- list(0)\n# for ( i in 1:F){\n#   Y.rel.sc.list[[i]] <- scale(Y.rel.list[[i]], center = TRUE, scale = TRUE)\n# }\n# \n# ## Irrelevant feature\n# Y.irrel.list <- list(0)\n# for ( i in 1:F){\n#   Y.irrel.list[[i]] <- Y.list[[i]][,-order.rel[[i]]]\n# }\n\n\n## The pure time is generated\ntime.pur.list <- list(0)\nfor ( i in 1:F){\n  time.pur.list[[i]] <- t(beta.list[[i]]) %*% t(Y.rel.sc.list[[i]])\n}\n\n## Simulating Time Data which is ONE dimensional\ntime.cluster <- MixSim(MaxOmega = prob.noise, K = F, p = 1, int =c(0,10))\n\ntime.noise.list <- list(0)\nfor ( i in 1:F){\n  time.noise.list[[i]] <- rnorm(as.integer(N * p.dist[i]), mean = time.cluster$Mu[i], sd = sqrt((time.cluster$S[i])))\n}\n\ntime.list <- list(0)\nfor ( i in 1:F){\n  time.list[[i]] <- time.pur.list[[i]] + time.noise.list[[i]]\n}\n\n\n### Combining the data with relevant and irrelevant columns\ndata.plain <- list(0) \nfor (i in 1:F){\n data.plain[[i]] <-  cbind(Y.rel.list[[i]], Y.irrel.list[[i]]) \n}\n\n\n### Making permutations with the order of the features\norder.list <- list(0)\nfor (i in 1:F){\n  order.list[[i]] <-  sample(D)\n}\n\n## Data is shuffled with respect to the features\ndata.schuffled <- list(0)\nfor (i in 1:F){\n  data.schuffled[[i]] <-  data.plain[[i]][,order.list[[i]]]\n}\n\n\n\n## True Labels for the points\nc.true <- c(0)\n for ( i in 1:F){\n c.true <- rbind(as.matrix(c.true) , as.matrix(c(rep(i, as.integer(N * p.dist[i])))))  \n}\nc.true <- as.factor(c.true[-1,])\n\n\n\n############################################### MAKING Y from the clusters data #####################3\nY <- c(0)\nfor (i in 1:F){\n  Y <- rbind(Y, data.schuffled[[i]])\n} \nY <- Y[-1,]\n\n\n\n#######################################MAKING TIME from cluster data ########################################################\ntime <- c(0)\nfor (i in 1:F){\n  time <- cbind(time, time.list[[i]])\n} \ntime <- time[,-1]\ntime <- as.vector(time)\n\n\n####################################### Adding CENSORING INFORMATION  ################################################################\n## Adding the censoring information\n\ncensoring <- rbinom(n = NROW(Y), size =1, prob = 1- prob.censoring)\nright.censoring.time <- min(time)  \n\n\nindex.time <- which(censoring==0)\nfor ( q in 1:length(index.time)){\n  time[index.time[q]] <- right.censoring.time\n  \n}\n\n### Making permutations also with order of the points\norder.points <- sample(N)\n\n\n\n## Adding the permuted order of points\nY <- Y[order.points,]\nc.true <- c.true[order.points]\ntime <- time[order.points]\n\n\n### A little Visualization of the Y Data ##############\npc <- prcomp(Y)\npc.pred <- predict(pc,newdata = Y)\nplot(pc.pred[,1], pc.pred[,2], pch = 19,col = c.true)\n\n## Boxplots for Vizualization of the time Data without censoring\nboxplot(time.list)\n\n\n### A Quick ManWhittney U test to check if the time's of the two cluster are significantly different\nwilcox.test(as.vector(time.list[[1]]), as.vector(time.list[[2]]), alternative = \"two.sided\")\n\n\n############################# PARAMETERS for GIBB's SAMPLING ######################################\n\niter = 500\niter.samples = 100\n\n################################# GIBBS SAMPLING  ###################################################\n\nTime <- cbind(time, censoring) \nD = NCOL(Y)\nN = NROW(Y)\nK = as.integer(N)\n\n## HYPER PRIORS\n## Hyper parameters of the DP\nshape.alpha <- 2\nrate.alpha <- 1\n## Hyperparameters for the GMM\nbeta  = D+2\nro = 0.5\n\n\nsource('rchinese.R')\nalpha  = rgamma(1, shape = shape.alpha, rate = rate.alpha )\nc <-  rchinese(N,alpha)\nf <- table(factor(c, levels = 1:max(c)))\n\n## Empirical Bayes Estimate of the Hyperparameters\nepsilon = as.vector(apply(Y,2,mean))\nW = cov(Y)\n\n\n## Initialization of the parameters for Gaussian Mixture\nmu = matrix(data = NA, nrow = K, ncol = D)\nS = array(data = NA, dim =c(K,D,D))\n\n\n#Sparsity controlling hyperparameter of the BAYESIAN LASSO MODEL\nr =1\nsi = 1.78\n\nlambda2 <- numeric(K)\ntau2 = matrix(data = NA, nrow = K, ncol = D)\nbetahat = matrix(data = NA, nrow = K, ncol = D)\nsigma2 <- rep(NA, K)\nbeta0 <- rep(NA, K)\nThat <-  numeric(N)\n\n## Fitting a linear model to the whole model\nYsc <- scale(Y[1:N,1:D], center = TRUE, scale =TRUE)\nlm.data <- lm(time ~ Ysc)\nsig2.dat <-  var(lm.data$residuals)\n\n\n## Set Some Initial Values for the Cluster Parameters\n\nsource('priordraw.R')\ndisclass <- table(factor(c, levels = 1:K))\nactiveclass <- which(disclass!=0)\nfor ( j in 1:length(activeclass)){\n  \n  priorone <- priordraw(beta, W, epsilon, ro, r, si, N, D, sig2.dat)  \n  mu[activeclass[j],] <- (priorone$mu) \n  S[activeclass[j],1:D,1:D]  <- priorone$Sigma  \n  beta0[activeclass[j]] <- priorone$beta0 \n  sigma2[activeclass[j]] <- priorone$sigma2\n  betahat[activeclass[j],1:D] <- priorone$betahat \n  lambda2[activeclass[j]] <- priorone$lambda2 \n  tau2[activeclass[j], 1:D] <- priorone$tau2\n}\n\n# The Time has to be initialized\nsource('updatetime.R')\nti <- updatetime(c, Y, Time,That, beta0, betahat, sigma2)\nThat <- ti$time\n\n\n## Initialization part for the parmaters of AFT Model with k-means and Bayesian Lasso\nsource('kmeansBlasso.R')\nkm <- kmeansBlasso(Y,That, F,K, beta, W, epsilon, ro, r, si, N, D, sig2.dat, c, mu, S, beta0, betahat, sigma2, lambda2, tau2)\nc <- km$c\nmu <- km$mu\nS <- km$S\nsigma2 <- km$sigma2\nbetahat <- km$betahat\nbeta0 <- km$beta0\nlambda2 <- km$lambda2\ntau2 <- km$tau2\n\n\n\n# Testing the  k-means estimate\nsource('predicttime.R')\ntime.predicted <- predicttime(c,Y, That,Time,beta0, betahat, sigma2)$predicttime\n\n\n## Prelimnary estimates of the RAND and C-INDEX index\nsource('calcindex.R')\ncindex <- calcindex(c,Time,time.predicted)$cindex\n\n## Adjusted Rand INDEX measure\nrandindex <- adjustedRandIndex(c.true,as.factor(c))\n\n\n\n\n## Gibb's sampling \n\nsource('posteriorchineseAFT.R')\nsource('posteriorGMMparametrs.R')\nsource('posteriortimeparameters.R')\nsource('updatetime.R')\nsource('priordraw.R')\nsource('likelihood.R')\n\n\ncognate <- NA\nparam <- NA\nparamtime <- NA\nloglike<- rep(0, iter)  \ntimeparam <- NA\ntime.predicted <- c(0)\ncindex <- c(0)\n\nprint(loglikelihood(c,Y,mu,S,alpha,That, beta0, betahat, sigma2, lambda2, tau2, K, epsilon, W, beta, ro,D, r, si, Time,N, sig2.dat) \n)\n\n\n\nfor (o in 1:iter) {\n  \n  \n  ################## PARAMETERS OF THE DP Mixture Model ######################################################\n  ## Updating the parameters based on the observations \n  param <- posteriorGMMparametrs(c,Y,mu,S, alpha,K, epsilon, W, beta, ro,N,D )\n  mu <- param$mean\n  S <- param$precision\n  paramtime <- posteriortimeparameters(c, That, lambda2,tau2,sigma2,beta0, betahat, Y, K, epsilon, W, beta, ro,D, r, si, Time,N, sig2.data)\n  beta0 <- paramtime$beta0\n  betahat <- paramtime$betahat\n  sigma2 <- paramtime$sigma2\n  lambda2 <- paramtime$lambda2\n  tau2 <- paramtime$tau2\n  \n  ########################## THE HYPERPARAMETERS OF THE GMM #################################  \n#   source('posteriorhyper.R')  \n#   #  Updating the hyper paramters\n#     hypercognate <- posteriorhyper (c, Y, mu, S, epsilon, W, beta, ro )\n#     epsilon <- hypercognate$epsilon\n#     W <- hypercognate$W\n#     W <- matrix(as.matrix(W),nrow = D, ncol =D)\n#     ro <- hypercognate$ro\n#     \n  ################# INDICATOR VARIABLE ##################################################################\n  ## Updating the indicator variables and the parameters\n  source('posteriorchineseAFT.R')\n  cognate <- posteriorchineseAFT(c,Y,mu,S,alpha,That, beta0, betahat, sigma2, lambda2, tau2, K, epsilon, W, beta, ro,D, r, si, Time,N, sig2.dat)\n  c <- cognate$indicator\n  mu <- cognate$mean\n  S <- cognate$precision\n  beta0 <- cognate$beta0\n  betahat <- cognate$betahat\n  sigma2 <- cognate$sigma2\n  lambda2 <- cognate$lambda2\n  tau2 <- cognate$tau2\n  \n  ########################### The Concentration Parameter #################################################################\n  \n  \n  #source('posterioralpha.R') \n  ## Updating the concentration parameter\n  # alpha <- posterioralpha(c, N, alpha, shape.alpha, rate.alpha)\n  \n  \n  ######################## The Censored Times ###########################################################\n  source('updatetime.R')\n  # Updating the Time Variable\n  ti <- NA\n  ti <- updatetime(c, Y, Time,That, beta0, betahat, sigma2)\n  That <- ti$time\n  \n  \n\n  ## Value of the predicted p-value\nsource('predicttime.R') \ntime.predicted <- predicttime(c, Y, That, Time, beta0, betahat, sigma2)$predicttime\n#  pval <- ks.test(That, time.predicted$predicttime, alternative = \"two.sided\" )$p.value\n source('calcindex.R')\n cindex <- calcindex(c,Time,time.predicted)$cindex\n  ## Value of the Log-likelihood\n  source('likelihood.R')\n  loglike[o] <-loglikelihood(c,Y,mu,S,alpha,That, beta0, betahat, sigma2, lambda2, tau2, K, epsilon, W, beta, ro,D, r, si, Time,N, sig2.dat) \n  \n  print(o/iter) \n  print(loglike[o])\n  print(cindex)\n} \n\n\n",
    "created" : 1428157978311.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2690642329",
    "id" : "3494A7A7",
    "lastKnownWriteTime" : 1428358487,
    "path" : "C:/Users/Oana-Ashar/Desktop/Dropbox/Code/DPmixturemodel/DPplusAFT/TEST.SIMULATIONS.GENERAL.R",
    "project_path" : "TEST.SIMULATIONS.GENERAL.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}